##  Capstone Disassembly Engine
##  By Nguyen Anh Quynh <aquynh@gmail.com>, 2013-2015

import
  platform

## / Calculate relative address for X86-64, given cs_insn structure

template X86_REL_ADDR*(insn: untyped): untyped =
  (if ((insn).detail.x86.operands[0].`type` == OP_IMM): (uint64_t)(
      (insn).detail.x86.operands[0].imm) else: (
      ((insn).address + (insn).size) + (uint64_t)(insn).detail.x86.disp))

## / X86 registers

type
  x86_reg* {.pure.} = enum
    INVALID = 0, AH, AL, AX, BH, BL,
    BP, BPL, BX, CH, CL, CS,
    CX, DH, DI, DIL, DL, DS,
    DX, EAX, EBP, EBX, ECX, EDI,
    EDX, EFLAGS, EIP, EIZ, ES, ESI,
    ESP, FPSW, FS, GS, IP, RAX,
    RBP, RBX, RCX, RDI, RDX, RIP,
    RIZ, RSI, RSP, SI, SIL, SP,
    SPL, SS, CR0, CR1, CR2, CR3,
    CR4, CR5, CR6, CR7, CR8, CR9,
    CR10, CR11, CR12, CR13, CR14,
    CR15, DR0, DR1, DR2, DR3, DR4,
    DR5, DR6, DR7, DR8, DR9, DR10,
    DR11, DR12, DR13, DR14, DR15,
    FP0, FP1, FP2, FP3, FP4, FP5,
    FP6, FP7, K0, K1, K2, K3,
    K4, K5, K6, K7, MM0, MM1,
    MM2, MM3, MM4, MM5, MM6, MM7,
    R8, R9, R10, R11, R12, R13,
    R14, R15, ST0, ST1, ST2, ST3,
    ST4, ST5, ST6, ST7, XMM0, XMM1,
    XMM2, XMM3, XMM4, XMM5, XMM6,
    XMM7, XMM8, XMM9, XMM10, XMM11,
    XMM12, XMM13, XMM14, XMM15, XMM16,
    XMM17, XMM18, XMM19, XMM20, XMM21,
    XMM22, XMM23, XMM24, XMM25, XMM26,
    XMM27, XMM28, XMM29, XMM30, XMM31,
    YMM0, YMM1, YMM2, YMM3, YMM4,
    YMM5, YMM6, YMM7, YMM8, YMM9,
    YMM10, YMM11, YMM12, YMM13, YMM14,
    YMM15, YMM16, YMM17, YMM18, YMM19,
    YMM20, YMM21, YMM22, YMM23, YMM24,
    YMM25, YMM26, YMM27, YMM28, YMM29,
    YMM30, YMM31, ZMM0, ZMM1, ZMM2,
    ZMM3, ZMM4, ZMM5, ZMM6, ZMM7,
    ZMM8, ZMM9, ZMM10, ZMM11, ZMM12,
    ZMM13, ZMM14, ZMM15, ZMM16, ZMM17,
    ZMM18, ZMM19, ZMM20, ZMM21, ZMM22,
    ZMM23, ZMM24, ZMM25, ZMM26, ZMM27,
    ZMM28, ZMM29, ZMM30, ZMM31, R8B,
    R9B, R10B, R11B, R12B, R13B,
    R14B, R15B, R8D, R9D, R10D, R11D,
    R12D, R13D, R14D, R15D, R8W, R9W,
    R10W, R11W, R12W, R13W, R14W,
    R15W, ENDING ##  <-- mark the end of the list of registers


##  Sub-flags of EFLAGS

## / Operand type for instruction's operands

type
  x86_op_type* {.pure.} = enum
    INVALID = 0           ## /< = CS_OP_INVALID (Uninitialized).
    REG               ## /< = CS_OP_REG (Register operand).
    IMM               ## /< = CS_OP_IMM (Immediate operand).
    MEM
    FP## /< = CS_OP_MEM (Memory operand).


## / AVX broadcast type

type
  x86_avx_bcast* {.pure.} = enum
    INVALID = 0,  ## /< Uninitialized.
    B2,          ## /< AVX512 broadcast type {1to2}
    B4,          ## /< AVX512 broadcast type {1to4}
    B8,          ## /< AVX512 broadcast type {1to8}
    B16          ## /< AVX512 broadcast type {1to16}


## / SSE Code Condition type

type
  x86_sse_cc* {.pure.} = enum
    INVALID = 0,     ## /< Uninitialized.
    EQ, LT, LE, UNORD, NEQ,
    NLT, NLE, ORD, EQ_UQ, NGE,
    NGT, FALSE, NEQ_OQ, GE,
    GT, TRUE


## / AVX Code Condition type

type
  x86_avx_cc* {.pure.} = enum
    INVALID = 0,     ## /< Uninitialized.
    EQ, LT, LE, UNORD, NEQ,
    NLT, NLE, ORD, EQ_UQ,
    NGE, NGT, FALSE, NEQ_OQ,
    GE, GT, TRUE, EQ_OS,
    LT_OQ, LE_OQ, UNORD_S, NEQ_US,
    NLT_UQ, NLE_UQ, ORD_S, EQ_US,
    NGE_UQ, NGT_UQ, FALSE_OS, NEQ_OS,
    GE_OQ, GT_OQ, TRUE_US


## / AVX static rounding mode type

type
  x86_avx_rm* {.pure.} = enum
    INVALID = 0,     ## /< Uninitialized.
    RN,            ## /< Round to nearest
    RD,            ## /< Round down
    RU,            ## /< Round up
    RZ             ## /< Round toward zero


## / Instruction prefixes - to be used in cs_x86.prefix[]

type
  x86_prefix* {.pure.} = enum
    INVALID = 0,
    ES = 0x26,       ## /< segment override ES (cs_x86.prefix[1]
    CS = 0x2e,       ## /< segment override CS (cs_x86.prefix[1]
    SS = 0x36,       ## /< segment override SS (cs_x86.prefix[1]
    DS = 0x3e,       ## /< segment override DS (cs_x86.prefix[1]
    FS = 0x64,       ## /< segment override FS (cs_x86.prefix[1]
    GS = 0x65,       ## /< segment override GS (cs_x86.prefix[1]
    OPSIZE = 0x66,   ## /< operand-size override (cs_x86.prefix[2]
    ADDRSIZE = 0x67, ## /< address-size override (cs_x86.prefix[3]
    LOCK = 0xf0,     ## /< lock (cs_x86.prefix[0]
    REPNE = 0xf2,    ## /< repne/repnz (cs_x86.prefix[0]
    REP = 0xf3       ## /< rep (cs_x86.prefix[0]


## / Instruction's operand referring to memory
## / This is associated with OP_MEM operand type above

type
  x86_op_mem* {.bycopy.} = object
    segment*: cuint         ## /< segment register (or INVALID if irrelevant)
    base*: cuint            ## /< base register (or INVALID if irrelevant)
    index*: cuint            ## /< index register (or INVALID if irrelevant)
    scale*: cint               ## /< scale for index register
    disp*: int64_t             ## /< displacement value


## / Instruction operand

type
  INNER_C_UNION_x86_296* {.bycopy, union.} = object
    reg*: x86_reg              ## /< register value for REG operand
    imm*: int64_t
    fp*: cdouble## /< immediate value for IMM operand
    mem*: x86_op_mem           ## /< base/index/scale/disp value for MEM operand

  cs_x86_op* {.bycopy.} = object
    `type`*: x86_op_type       ## /< operand type
    storage*: INNER_C_UNION_x86_296
    size*: uint8_t ## / How is this operand accessed? (READ, WRITE or READ|WRITE)
                 ## / This field is combined of cs_ac_type.
                 ## / NOTE: this field is irrelevant if engine is compiled in DIET mode.
    avx_bcast*: x86_avx_bcast  ## / AVX zero opmask {z}
    avx_zero_opmask*: bool



## / Instruction structure

type
  cs_x86* {.bycopy.} = object
    prefix*: array[4, uint8_t]
    opcode*: array[4, uint8_t]  ## / REX prefix: only a non-zero value is relevant for x86_64
    rex*: uint8_t            ## / Address size, which can be overridden with above prefix[5].
    addr_size*: uint8_t
    ## / ModR/M byte
    modrm*: uint8_t
    ## / SIB value, or 0 when irrelevant.
    sib*: uint8_t
    ## / Displacement value, valid if encoding.disp_offset != 0
    disp*: int32_t
    ## / SIB index register, or INVALID when irrelevant.
    sib_index*: x86_reg        ## / SIB scale, only applicable if sib_index is valid.
    sib_scale*: int8_t         ## / SIB base register, or INVALID when irrelevant.
    sib_base*: x86_reg         ## / XOP Code Condition

    # xop_cc*: x86_xop_cc        ## / SSE Code Condition
    sse_cc*: x86_sse_cc        ## / AVX Code Condition
    avx_cc*: x86_avx_cc        ## / AVX Suppress all Exception
    avx_sae*: bool             ## / AVX static rounding mode
    avx_rm*: x86_avx_rm
    # flags*: INNER_C_UNION_x86_381
    op_count*: uint8_t
    operands*: array[8, cs_x86_op] ## /< operands for this instruction.
    # encoding*: cs_x86_encoding ## /< encoding information


static:
  var accessOffset = 0

  for key, val in fieldPairs(cs_x86()):
    echo "[X86] ", key, ": ", accessOffset

    accessOffset.inc sizeof(val)

## / X86 instructions

type
  x86_insn* {.pure.} = enum
    INVALID = 0, AAA, AAD, AAM, AAS,
    FABS, ADC, ADCX, ADD, ADDPD,
    ADDPS, ADDSD, ADDSS, ADDSUBPD, ADDSUBPS,
    FADD, FIADD, FADDP, ADOX, AESDECLAST,
    AESDEC, AESENCLAST, AESENC, AESIMC,
    AESKEYGENASSIST, AND, ANDN, ANDNPD,
    ANDNPS, ANDPD, ANDPS, ARPL, BEXTR,
    BLCFILL, BLCI, BLCIC, BLCMSK, BLCS,
    BLENDPD, BLENDPS, BLENDVPD, BLENDVPS,
    BLSFILL, BLSI, BLSIC, BLSMSK, BLSR,
    BOUND, BSF, BSR, BSWAP, BT, BTC,
    BTR, BTS, BZHI, CALL, CBW, CDQ,
    CDQE, FCHS, CLAC, CLC, CLD,
    CLFLUSH, CLFLUSHOPT, CLGI, CLI, CLTS,
    CLWB, CMC, CMOVA, CMOVAE, CMOVB,
    CMOVBE, FCMOVBE, FCMOVB, CMOVE, FCMOVE,
    CMOVG, CMOVGE, CMOVL, CMOVLE, FCMOVNBE,
    FCMOVNB, CMOVNE, FCMOVNE, CMOVNO,
    CMOVNP, FCMOVNU, CMOVNS, CMOVO, CMOVP,
    FCMOVU, CMOVS, CMP, CMPSB, CMPSQ,
    CMPSW, CMPXCHG16B, CMPXCHG, CMPXCHG8B,
    COMISD, COMISS, FCOMP, FCOMIP, FCOMI,
    FCOM, FCOS, CPUID, CQO, CRC32,
    CVTDQ2PD, CVTDQ2PS, CVTPD2DQ, CVTPD2PS,
    CVTPS2DQ, CVTPS2PD, CVTSD2SI, CVTSD2SS,
    CVTSI2SD, CVTSI2SS, CVTSS2SD, CVTSS2SI,
    CVTTPD2DQ, CVTTPS2DQ, CVTTSD2SI, CVTTSS2SI,
    CWD, CWDE, DAA, DAS, DATA16, DEC,
    DIV, DIVPD, DIVPS, FDIVR, FIDIVR,
    FDIVRP, DIVSD, DIVSS, FDIV, FIDIV,
    FDIVP, DPPD, DPPS, RET, ENCLS,
    ENCLU, ENTER, EXTRACTPS, EXTRQ, F2XM1,
    LCALL, LJMP, FBLD, FBSTP, FCOMPP,
    FDECSTP, FEMMS, FFREE, FICOM, FICOMP,
    FINCSTP, FLDCW, FLDENV, FLDL2E, FLDL2T,
    FLDLG2, FLDLN2, FLDPI, FNCLEX, FNINIT,
    FNOP, FNSTCW, FNSTSW, FPATAN, FPREM,
    FPREM1, FPTAN, FFREEP, FRNDINT, FRSTOR,
    FNSAVE, FSCALE, FSETPM, FSINCOS,
    FNSTENV, FXAM, FXRSTOR, FXRSTOR64,
    FXSAVE, FXSAVE64, FXTRACT, FYL2X,
    FYL2XP1, MOVAPD, MOVAPS, ORPD, ORPS,
    VMOVAPD, VMOVAPS, XORPD, XORPS, GETSEC,
    HADDPD, HADDPS, HLT, HSUBPD, HSUBPS,
    IDIV, FILD, IMUL, IN, INC, INSB,
    INSERTPS, INSERTQ, INSD, INSW, INT,
    INT1, INT3, INTO, INVD, INVEPT,
    INVLPG, INVLPGA, INVPCID, INVVPID, IRET,
    IRETD, IRETQ, FISTTP, FIST, FISTP,
    UCOMISD, UCOMISS, VCOMISD, VCOMISS,
    VCVTSD2SS, VCVTSI2SD, VCVTSI2SS, VCVTSS2SD,
    VCVTTSD2SI, VCVTTSD2USI, VCVTTSS2SI,
    VCVTTSS2USI, VCVTUSI2SD, VCVTUSI2SS, VUCOMISD,
    VUCOMISS, JAE, JA, JBE, JB, JCXZ,
    JECXZ, JE, JGE, JG, JLE, JL,
    JMP, JNE, JNO, JNP, JNS, JO,
    JP, JRCXZ, JS, KANDB, KANDD,
    KANDNB, KANDND, KANDNQ, KANDNW, KANDQ,
    KANDW, KMOVB, KMOVD, KMOVQ, KMOVW,
    KNOTB, KNOTD, KNOTQ, KNOTW, KORB,
    KORD, KORQ, KORTESTB, KORTESTD,
    KORTESTQ, KORTESTW, KORW, KSHIFTLB,
    KSHIFTLD, KSHIFTLQ, KSHIFTLW, KSHIFTRB,
    KSHIFTRD, KSHIFTRQ, KSHIFTRW, KUNPCKBW,
    KXNORB, KXNORD, KXNORQ, KXNORW, KXORB,
    KXORD, KXORQ, KXORW, LAHF, LAR,
    LDDQU, LDMXCSR, LDS, FLDZ, FLD1,
    FLD, LEA, LEAVE, LES, LFENCE,
    LFS, LGDT, LGS, LIDT, LLDT, LMSW,
    OR, SUB, XOR, LODSB, LODSD,
    LODSQ, LODSW, LOOP, LOOPE, LOOPNE,
    RETF, RETFQ, LSL, LSS, LTR, XADD,
    LZCNT, MASKMOVDQU, MAXPD, MAXPS, MAXSD,
    MAXSS, MFENCE, MINPD, MINPS, MINSD,
    MINSS, CVTPD2PI, CVTPI2PD, CVTPI2PS,
    CVTPS2PI, CVTTPD2PI, CVTTPS2PI, EMMS,
    MASKMOVQ, MOVD, MOVDQ2Q, MOVNTQ,
    MOVQ2DQ, MOVQ, PABSB, PABSD, PABSW,
    PACKSSDW, PACKSSWB, PACKUSWB, PADDB,
    PADDD, PADDQ, PADDSB, PADDSW, PADDUSB,
    PADDUSW, PADDW, PALIGNR, PANDN, PAND,
    PAVGB, PAVGW, PCMPEQB, PCMPEQD, PCMPEQW,
    PCMPGTB, PCMPGTD, PCMPGTW, PEXTRW,
    PHADDSW, PHADDW, PHADDD, PHSUBD,
    PHSUBSW, PHSUBW, PINSRW, PMADDUBSW,
    PMADDWD, PMAXSW, PMAXUB, PMINSW, PMINUB,
    PMOVMSKB, PMULHRSW, PMULHUW, PMULHW,
    PMULLW, PMULUDQ, POR, PSADBW, PSHUFB,
    PSHUFW, PSIGNB, PSIGND, PSIGNW, PSLLD,
    PSLLQ, PSLLW, PSRAD, PSRAW, PSRLD,
    PSRLQ, PSRLW, PSUBB, PSUBD, PSUBQ,
    PSUBSB, PSUBSW, PSUBUSB, PSUBUSW, PSUBW,
    PUNPCKHBW, PUNPCKHDQ, PUNPCKHWD, PUNPCKLBW,
    PUNPCKLDQ, PUNPCKLWD, PXOR, MONITOR,
    MONTMUL, MOV, MOVABS, MOVBE, MOVDDUP,
    MOVDQA, MOVDQU, MOVHLPS, MOVHPD, MOVHPS,
    MOVLHPS, MOVLPD, MOVLPS, MOVMSKPD,
    MOVMSKPS, MOVNTDQA, MOVNTDQ, MOVNTI,
    MOVNTPD, MOVNTPS, MOVNTSD, MOVNTSS,
    MOVSB, MOVSD, MOVSHDUP, MOVSLDUP, MOVSQ,
    MOVSS, MOVSW, MOVSX, MOVSXD, MOVUPD,
    MOVUPS, MOVZX, MPSADBW, MUL, MULPD,
    MULPS, MULSD, MULSS, MULX, FMUL,
    FIMUL, FMULP, MWAIT, NEG, NOP,
    NOT, OUT, OUTSB, OUTSD, OUTSW,
    PACKUSDW, PAUSE, PAVGUSB, PBLENDVB,
    PBLENDW, PCLMULQDQ, PCMPEQQ, PCMPESTRI,
    PCMPESTRM, PCMPGTQ, PCMPISTRI, PCMPISTRM,
    PCOMMIT, PDEP, PEXT, PEXTRB, PEXTRD,
    PEXTRQ, PF2ID, PF2IW, PFACC, PFADD,
    PFCMPEQ, PFCMPGE, PFCMPGT, PFMAX, PFMIN,
    PFMUL, PFNACC, PFPNACC, PFRCPIT1,
    PFRCPIT2, PFRCP, PFRSQIT1, PFRSQRT,
    PFSUBR, PFSUB, PHMINPOSUW, PI2FD, PI2FW,
    PINSRB, PINSRD, PINSRQ, PMAXSB, PMAXSD,
    PMAXUD, PMAXUW, PMINSB, PMINSD, PMINUD,
    PMINUW, PMOVSXBD, PMOVSXBQ, PMOVSXBW,
    PMOVSXDQ, PMOVSXWD, PMOVSXWQ, PMOVZXBD,
    PMOVZXBQ, PMOVZXBW, PMOVZXDQ, PMOVZXWD,
    PMOVZXWQ, PMULDQ, PMULHRW, PMULLD, POP,
    POPAW, POPAL, POPCNT, POPF, POPFD,
    POPFQ, PREFETCH, PREFETCHNTA, PREFETCHT0,
    PREFETCHT1, PREFETCHT2, PREFETCHW, PSHUFD,
    PSHUFHW, PSHUFLW, PSLLDQ, PSRLDQ,
    PSWAPD, PTEST, PUNPCKHQDQ, PUNPCKLQDQ,
    PUSH, PUSHAW, PUSHAL, PUSHF, PUSHFD,
    PUSHFQ, RCL, RCPPS, RCPSS, RCR,
    RDFSBASE, RDGSBASE, RDMSR, RDPMC,
    RDRAND, RDSEED, RDTSC, RDTSCP, ROL,
    ROR, RORX, ROUNDPD, ROUNDPS, ROUNDSD,
    ROUNDSS, RSM, RSQRTPS, RSQRTSS, SAHF,
    SAL, SALC, SAR, SARX, SBB, SCASB,
    SCASD, SCASQ, SCASW, SETAE, SETA,
    SETBE, SETB, SETE, SETGE, SETG,
    SETLE, SETL, SETNE, SETNO, SETNP,
    SETNS, SETO, SETP, SETS, SFENCE,
    SGDT, SHA1MSG1, SHA1MSG2, SHA1NEXTE,
    SHA1RNDS4, SHA256MSG1, SHA256MSG2, SHA256RNDS2,
    SHL, SHLD, SHLX, SHR, SHRD, SHRX,
    SHUFPD, SHUFPS, SIDT, FSIN, SKINIT,
    SLDT, SMSW, SQRTPD, SQRTPS, SQRTSD,
    SQRTSS, FSQRT, STAC, STC, STD,
    STGI, STI, STMXCSR, STOSB, STOSD,
    STOSQ, STOSW, STR, FST, FSTP,
    FSTPNCE, FXCH, SUBPD, SUBPS, FSUBR,
    FISUBR, FSUBRP, SUBSD, SUBSS, FSUB,
    FISUB, FSUBP, SWAPGS, SYSCALL, SYSENTER,
    SYSEXIT, SYSRET, T1MSKC, TEST, UD2,
    FTST, TZCNT, TZMSK, FUCOMIP, FUCOMI,
    FUCOMPP, FUCOMP, FUCOM, UD2B, UNPCKHPD,
    UNPCKHPS, UNPCKLPD, UNPCKLPS, VADDPD,
    VADDPS, VADDSD, VADDSS, VADDSUBPD,
    VADDSUBPS, VAESDECLAST, VAESDEC, VAESENCLAST,
    VAESENC, VAESIMC, VAESKEYGENASSIST, VALIGND,
    VALIGNQ, VANDNPD, VANDNPS, VANDPD,
    VANDPS, VBLENDMPD, VBLENDMPS, VBLENDPD,
    VBLENDPS, VBLENDVPD, VBLENDVPS, VBROADCASTF128,
    VBROADCASTI32X4, VBROADCASTI64X4, VBROADCASTSD,
    VBROADCASTSS, VCOMPRESSPD, VCOMPRESSPS,
    VCVTDQ2PD, VCVTDQ2PS, VCVTPD2DQX, VCVTPD2DQ,
    VCVTPD2PSX, VCVTPD2PS, VCVTPD2UDQ, VCVTPH2PS,
    VCVTPS2DQ, VCVTPS2PD, VCVTPS2PH, VCVTPS2UDQ,
    VCVTSD2SI, VCVTSD2USI, VCVTSS2SI, VCVTSS2USI,
    VCVTTPD2DQX, VCVTTPD2DQ, VCVTTPD2UDQ,
    VCVTTPS2DQ, VCVTTPS2UDQ, VCVTUDQ2PD,
    VCVTUDQ2PS, VDIVPD, VDIVPS, VDIVSD,
    VDIVSS, VDPPD, VDPPS, VERR, VERW,
    VEXP2PD, VEXP2PS, VEXPANDPD, VEXPANDPS,
    VEXTRACTF128, VEXTRACTF32X4, VEXTRACTF64X4,
    VEXTRACTI128, VEXTRACTI32X4, VEXTRACTI64X4,
    VEXTRACTPS, VFMADD132PD, VFMADD132PS, VFMADDPD,
    VFMADD213PD, VFMADD231PD, VFMADDPS,
    VFMADD213PS, VFMADD231PS, VFMADDSD,
    VFMADD213SD, VFMADD132SD, VFMADD231SD,
    VFMADDSS, VFMADD213SS, VFMADD132SS,
    VFMADD231SS, VFMADDSUB132PD, VFMADDSUB132PS,
    VFMADDSUBPD, VFMADDSUB213PD, VFMADDSUB231PD,
    VFMADDSUBPS, VFMADDSUB213PS, VFMADDSUB231PS,
    VFMSUB132PD, VFMSUB132PS, VFMSUBADD132PD,
    VFMSUBADD132PS, VFMSUBADDPD, VFMSUBADD213PD,
    VFMSUBADD231PD, VFMSUBADDPS, VFMSUBADD213PS,
    VFMSUBADD231PS, VFMSUBPD, VFMSUB213PD,
    VFMSUB231PD, VFMSUBPS, VFMSUB213PS,
    VFMSUB231PS, VFMSUBSD, VFMSUB213SD,
    VFMSUB132SD, VFMSUB231SD, VFMSUBSS,
    VFMSUB213SS, VFMSUB132SS, VFMSUB231SS,
    VFNMADD132PD, VFNMADD132PS, VFNMADDPD,
    VFNMADD213PD, VFNMADD231PD, VFNMADDPS,
    VFNMADD213PS, VFNMADD231PS, VFNMADDSD,
    VFNMADD213SD, VFNMADD132SD, VFNMADD231SD,
    VFNMADDSS, VFNMADD213SS, VFNMADD132SS,
    VFNMADD231SS, VFNMSUB132PD, VFNMSUB132PS,
    VFNMSUBPD, VFNMSUB213PD, VFNMSUB231PD,
    VFNMSUBPS, VFNMSUB213PS, VFNMSUB231PS,
    VFNMSUBSD, VFNMSUB213SD, VFNMSUB132SD,
    VFNMSUB231SD, VFNMSUBSS, VFNMSUB213SS,
    VFNMSUB132SS, VFNMSUB231SS, VFRCZPD, VFRCZPS,
    VFRCZSD, VFRCZSS, VORPD, VORPS, VXORPD,
    VXORPS, VGATHERDPD, VGATHERDPS, VGATHERPF0DPD,
    VGATHERPF0DPS, VGATHERPF0QPD, VGATHERPF0QPS,
    VGATHERPF1DPD, VGATHERPF1DPS, VGATHERPF1QPD,
    VGATHERPF1QPS, VGATHERQPD, VGATHERQPS, VHADDPD,
    VHADDPS, VHSUBPD, VHSUBPS, VINSERTF128,
    VINSERTF32X4, VINSERTF32X8, VINSERTF64X2,
    VINSERTF64X4, VINSERTI128, VINSERTI32X4,
    VINSERTI32X8, VINSERTI64X2, VINSERTI64X4,
    VINSERTPS, VLDDQU, VLDMXCSR, VMASKMOVDQU,
    VMASKMOVPD, VMASKMOVPS, VMAXPD, VMAXPS,
    VMAXSD, VMAXSS, VMCALL, VMCLEAR, VMFUNC,
    VMINPD, VMINPS, VMINSD, VMINSS,
    VMLAUNCH, VMLOAD, VMMCALL, VMOVQ,
    VMOVDDUP, VMOVD, VMOVDQA32, VMOVDQA64,
    VMOVDQA, VMOVDQU16, VMOVDQU32, VMOVDQU64,
    VMOVDQU8, VMOVDQU, VMOVHLPS, VMOVHPD,
    VMOVHPS, VMOVLHPS, VMOVLPD, VMOVLPS,
    VMOVMSKPD, VMOVMSKPS, VMOVNTDQA, VMOVNTDQ,
    VMOVNTPD, VMOVNTPS, VMOVSD, VMOVSHDUP,
    VMOVSLDUP, VMOVSS, VMOVUPD, VMOVUPS,
    VMPSADBW, VMPTRLD, VMPTRST, VMREAD,
    VMRESUME, VMRUN, VMSAVE, VMULPD, VMULPS,
    VMULSD, VMULSS, VMWRITE, VMXOFF, VMXON,
    VPABSB, VPABSD, VPABSQ, VPABSW,
    VPACKSSDW, VPACKSSWB, VPACKUSDW, VPACKUSWB,
    VPADDB, VPADDD, VPADDQ, VPADDSB,
    VPADDSW, VPADDUSB, VPADDUSW, VPADDW,
    VPALIGNR, VPANDD, VPANDND, VPANDNQ,
    VPANDN, VPANDQ, VPAND, VPAVGB, VPAVGW,
    VPBLENDD, VPBLENDMB, VPBLENDMD, VPBLENDMQ,
    VPBLENDMW, VPBLENDVB, VPBLENDW, VPBROADCASTB,
    VPBROADCASTD, VPBROADCASTMB2Q, VPBROADCASTMW2D,
    VPBROADCASTQ, VPBROADCASTW, VPCLMULQDQ, VPCMOV,
    VPCMPB, VPCMPD, VPCMPEQB, VPCMPEQD,
    VPCMPEQQ, VPCMPEQW, VPCMPESTRI, VPCMPESTRM,
    VPCMPGTB, VPCMPGTD, VPCMPGTQ, VPCMPGTW,
    VPCMPISTRI, VPCMPISTRM, VPCMPQ, VPCMPUB,
    VPCMPUD, VPCMPUQ, VPCMPUW, VPCMPW,
    VPCOMB, VPCOMD, VPCOMPRESSD, VPCOMPRESSQ,
    VPCOMQ, VPCOMUB, VPCOMUD, VPCOMUQ,
    VPCOMUW, VPCOMW, VPCONFLICTD, VPCONFLICTQ,
    VPERM2F128, VPERM2I128, VPERMD, VPERMI2D,
    VPERMI2PD, VPERMI2PS, VPERMI2Q, VPERMIL2PD,
    VPERMIL2PS, VPERMILPD, VPERMILPS, VPERMPD,
    VPERMPS, VPERMQ, VPERMT2D, VPERMT2PD,
    VPERMT2PS, VPERMT2Q, VPEXPANDD, VPEXPANDQ,
    VPEXTRB, VPEXTRD, VPEXTRQ, VPEXTRW,
    VPGATHERDD, VPGATHERDQ, VPGATHERQD, VPGATHERQQ,
    VPHADDBD, VPHADDBQ, VPHADDBW, VPHADDDQ,
    VPHADDD, VPHADDSW, VPHADDUBD, VPHADDUBQ,
    VPHADDUBW, VPHADDUDQ, VPHADDUWD, VPHADDUWQ,
    VPHADDWD, VPHADDWQ, VPHADDW, VPHMINPOSUW,
    VPHSUBBW, VPHSUBDQ, VPHSUBD, VPHSUBSW,
    VPHSUBWD, VPHSUBW, VPINSRB, VPINSRD,
    VPINSRQ, VPINSRW, VPLZCNTD, VPLZCNTQ,
    VPMACSDD, VPMACSDQH, VPMACSDQL, VPMACSSDD,
    VPMACSSDQH, VPMACSSDQL, VPMACSSWD, VPMACSSWW,
    VPMACSWD, VPMACSWW, VPMADCSSWD, VPMADCSWD,
    VPMADDUBSW, VPMADDWD, VPMASKMOVD, VPMASKMOVQ,
    VPMAXSB, VPMAXSD, VPMAXSQ, VPMAXSW,
    VPMAXUB, VPMAXUD, VPMAXUQ, VPMAXUW,
    VPMINSB, VPMINSD, VPMINSQ, VPMINSW,
    VPMINUB, VPMINUD, VPMINUQ, VPMINUW,
    VPMOVDB, VPMOVDW, VPMOVM2B, VPMOVM2D,
    VPMOVM2Q, VPMOVM2W, VPMOVMSKB, VPMOVQB,
    VPMOVQD, VPMOVQW, VPMOVSDB, VPMOVSDW,
    VPMOVSQB, VPMOVSQD, VPMOVSQW, VPMOVSXBD,
    VPMOVSXBQ, VPMOVSXBW, VPMOVSXDQ, VPMOVSXWD,
    VPMOVSXWQ, VPMOVUSDB, VPMOVUSDW, VPMOVUSQB,
    VPMOVUSQD, VPMOVUSQW, VPMOVZXBD, VPMOVZXBQ,
    VPMOVZXBW, VPMOVZXDQ, VPMOVZXWD, VPMOVZXWQ,
    VPMULDQ, VPMULHRSW, VPMULHUW, VPMULHW,
    VPMULLD, VPMULLQ, VPMULLW, VPMULUDQ,
    VPORD, VPORQ, VPOR, VPPERM, VPROTB,
    VPROTD, VPROTQ, VPROTW, VPSADBW,
    VPSCATTERDD, VPSCATTERDQ, VPSCATTERQD,
    VPSCATTERQQ, VPSHAB, VPSHAD, VPSHAQ,
    VPSHAW, VPSHLB, VPSHLD, VPSHLQ, VPSHLW,
    VPSHUFB, VPSHUFD, VPSHUFHW, VPSHUFLW,
    VPSIGNB, VPSIGND, VPSIGNW, VPSLLDQ,
    VPSLLD, VPSLLQ, VPSLLVD, VPSLLVQ,
    VPSLLW, VPSRAD, VPSRAQ, VPSRAVD,
    VPSRAVQ, VPSRAW, VPSRLDQ, VPSRLD,
    VPSRLQ, VPSRLVD, VPSRLVQ, VPSRLW,
    VPSUBB, VPSUBD, VPSUBQ, VPSUBSB,
    VPSUBSW, VPSUBUSB, VPSUBUSW, VPSUBW,
    VPTESTMD, VPTESTMQ, VPTESTNMD, VPTESTNMQ,
    VPTEST, VPUNPCKHBW, VPUNPCKHDQ, VPUNPCKHQDQ,
    VPUNPCKHWD, VPUNPCKLBW, VPUNPCKLDQ,
    VPUNPCKLQDQ, VPUNPCKLWD, VPXORD, VPXORQ,
    VPXOR, VRCP14PD, VRCP14PS, VRCP14SD,
    VRCP14SS, VRCP28PD, VRCP28PS, VRCP28SD,
    VRCP28SS, VRCPPS, VRCPSS, VRNDSCALEPD,
    VRNDSCALEPS, VRNDSCALESD, VRNDSCALESS,
    VROUNDPD, VROUNDPS, VROUNDSD, VROUNDSS,
    VRSQRT14PD, VRSQRT14PS, VRSQRT14SD, VRSQRT14SS,
    VRSQRT28PD, VRSQRT28PS, VRSQRT28SD, VRSQRT28SS,
    VRSQRTPS, VRSQRTSS, VSCATTERDPD, VSCATTERDPS,
    VSCATTERPF0DPD, VSCATTERPF0DPS, VSCATTERPF0QPD,
    VSCATTERPF0QPS, VSCATTERPF1DPD, VSCATTERPF1DPS,
    VSCATTERPF1QPD, VSCATTERPF1QPS, VSCATTERQPD,
    VSCATTERQPS, VSHUFPD, VSHUFPS, VSQRTPD,
    VSQRTPS, VSQRTSD, VSQRTSS, VSTMXCSR,
    VSUBPD, VSUBPS, VSUBSD, VSUBSS, VTESTPD,
    VTESTPS, VUNPCKHPD, VUNPCKHPS, VUNPCKLPD,
    VUNPCKLPS, VZEROALL, VZEROUPPER, WAIT,
    WBINVD, WRFSBASE, WRGSBASE, WRMSR,
    XABORT, XACQUIRE, XBEGIN, XCHG,
    XCRYPTCBC, XCRYPTCFB, XCRYPTCTR, XCRYPTECB,
    XCRYPTOFB, XEND, XGETBV, XLATB,
    XRELEASE, XRSTOR, XRSTOR64, XRSTORS,
    XRSTORS64, XSAVE, XSAVE64, XSAVEC,
    XSAVEC64, XSAVEOPT, XSAVEOPT64, XSAVES,
    XSAVES64, XSETBV, XSHA1, XSHA256,
    XSTORE, XTEST, FDISI8087_NOP, FENI8087_NOP, ##  pseudo instructions
    CMPSS, CMPEQSS, CMPLTSS, CMPLESS,
    CMPUNORDSS, CMPNEQSS, CMPNLTSS, CMPNLESS,
    CMPORDSS, CMPSD, CMPEQSD, CMPLTSD,
    CMPLESD, CMPUNORDSD, CMPNEQSD, CMPNLTSD,
    CMPNLESD, CMPORDSD, CMPPS, CMPEQPS,
    CMPLTPS, CMPLEPS, CMPUNORDPS, CMPNEQPS,
    CMPNLTPS, CMPNLEPS, CMPORDPS, CMPPD,
    CMPEQPD, CMPLTPD, CMPLEPD, CMPUNORDPD,
    CMPNEQPD, CMPNLTPD, CMPNLEPD, CMPORDPD,
    VCMPSS, VCMPEQSS, VCMPLTSS, VCMPLESS,
    VCMPUNORDSS, VCMPNEQSS, VCMPNLTSS, VCMPNLESS,
    VCMPORDSS, VCMPEQ_UQSS, VCMPNGESS, VCMPNGTSS,
    VCMPFALSESS, VCMPNEQ_OQSS, VCMPGESS, VCMPGTSS,
    VCMPTRUESS, VCMPEQ_OSSS, VCMPLT_OQSS,
    VCMPLE_OQSS, VCMPUNORD_SSS, VCMPNEQ_USSS,
    VCMPNLT_UQSS, VCMPNLE_UQSS, VCMPORD_SSS,
    VCMPEQ_USSS, VCMPNGE_UQSS, VCMPNGT_UQSS,
    VCMPFALSE_OSSS, VCMPNEQ_OSSS, VCMPGE_OQSS,
    VCMPGT_OQSS, VCMPTRUE_USSS, VCMPSD, VCMPEQSD,
    VCMPLTSD, VCMPLESD, VCMPUNORDSD, VCMPNEQSD,
    VCMPNLTSD, VCMPNLESD, VCMPORDSD, VCMPEQ_UQSD,
    VCMPNGESD, VCMPNGTSD, VCMPFALSESD,
    VCMPNEQ_OQSD, VCMPGESD, VCMPGTSD, VCMPTRUESD,
    VCMPEQ_OSSD, VCMPLT_OQSD, VCMPLE_OQSD,
    VCMPUNORD_SSD, VCMPNEQ_USSD, VCMPNLT_UQSD,
    VCMPNLE_UQSD, VCMPORD_SSD, VCMPEQ_USSD,
    VCMPNGE_UQSD, VCMPNGT_UQSD, VCMPFALSE_OSSD,
    VCMPNEQ_OSSD, VCMPGE_OQSD, VCMPGT_OQSD,
    VCMPTRUE_USSD, VCMPPS, VCMPEQPS, VCMPLTPS,
    VCMPLEPS, VCMPUNORDPS, VCMPNEQPS, VCMPNLTPS,
    VCMPNLEPS, VCMPORDPS, VCMPEQ_UQPS, VCMPNGEPS,
    VCMPNGTPS, VCMPFALSEPS, VCMPNEQ_OQPS, VCMPGEPS,
    VCMPGTPS, VCMPTRUEPS, VCMPEQ_OSPS, VCMPLT_OQPS,
    VCMPLE_OQPS, VCMPUNORD_SPS, VCMPNEQ_USPS,
    VCMPNLT_UQPS, VCMPNLE_UQPS, VCMPORD_SPS,
    VCMPEQ_USPS, VCMPNGE_UQPS, VCMPNGT_UQPS,
    VCMPFALSE_OSPS, VCMPNEQ_OSPS, VCMPGE_OQPS,
    VCMPGT_OQPS, VCMPTRUE_USPS, VCMPPD, VCMPEQPD,
    VCMPLTPD, VCMPLEPD, VCMPUNORDPD, VCMPNEQPD,
    VCMPNLTPD, VCMPNLEPD, VCMPORDPD, VCMPEQ_UQPD,
    VCMPNGEPD, VCMPNGTPD, VCMPFALSEPD,
    VCMPNEQ_OQPD, VCMPGEPD, VCMPGTPD, VCMPTRUEPD,
    VCMPEQ_OSPD, VCMPLT_OQPD, VCMPLE_OQPD,
    VCMPUNORD_SPD, VCMPNEQ_USPD, VCMPNLT_UQPD,
    VCMPNLE_UQPD, VCMPORD_SPD, VCMPEQ_USPD,
    VCMPNGE_UQPD, VCMPNGT_UQPD, VCMPFALSE_OSPD,
    VCMPNEQ_OSPD, VCMPGE_OQPD, VCMPGT_OQPD,
    VCMPTRUE_USPD, UD0, ENDBR32, ENDBR64, ENDING ##  mark the end of the list of insn


## / Group of X86 instructions

type
  x86_insn_group* {.pure.} = enum
    INVALID = 0,        ## /< = CS_INVALID
                      ##  Generic groups
                      ##  all jump instructions (conditional+direct+indirect jumps)
    JUMP,             ## /< = CS_JUMP
                 ##  all call instructions
    CALL,             ## /< = CS_CALL
                 ##  all return instructions
    RET,              ## /< = CS_RET
                ##  all interrupt instructions (int+syscall)
    INT,              ## /< = CS_INT
                ##  all interrupt return instructions
    IRET,             ## /< = CS_IRET
                 ##  all privileged instructions
    PRIVILEGE,        ## /< = CS_PRIVILEGE
                      ##  all relative branching instructions
    BRANCH_RELATIVE,  ## /< = CS_BRANCH_RELATIVE
                            ##  Architecture-specific groups
    VM = 128,           ## /< all virtualization instructions (VT-x + AMD-V)
    THREEDNOW, AES, ADX, AVX, AVX2,
    AVX512, BMI, BMI2, CMOV, F16C,
    FMA, FMA4, FSGSBASE, HLE, MMX,
    MODE32, MODE64, RTM, SHA, SSE1,
    SSE2, SSE3, SSE41, SSE42, SSE4A,
    SSSE3, PCLMUL, XOP, CDI, ERI,
    TBM, SIXTEEN_BITMODE, NOT64BITMODE, SGX, DQI,
    BWI, PFI, VLX, SMAP, NOVLX, FPU,
    ENDING

