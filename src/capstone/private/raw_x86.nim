##  Capstone Disassembly Engine
##  By Nguyen Anh Quynh <aquynh@gmail.com>, 2013-2015

import
  platform

## / Calculate relative address for X86-64, given cs_insn structure

template X86_REL_ADDR*(insn: untyped): untyped =
  (if ((insn).detail.x86.operands[0].`type` == OP_IMM): (uint64_t)(
      (insn).detail.x86.operands[0].imm) else: (
      ((insn).address + (insn).size) + (uint64_t)(insn).detail.x86.disp))

## / X86 registers

type
  x86_reg* {.pure.} = enum
    INVALID = 0, AH, AL, AX, BH, BL,
    BP, BPL, BX, CH, CL, CS,
    CX, DH, DI, DIL, DL, DS,
    DX, EAX, EBP, EBX, ECX, EDI,
    EDX, EFLAGS, EIP, EIZ, ES, ESI,
    ESP, FPSW, FS, GS, IP, RAX,
    RBP, RBX, RCX, RDI, RDX, RIP,
    RIZ, RSI, RSP, SI, SIL, SP,
    SPL, SS, CR0, CR1, CR2, CR3,
    CR4, CR5, CR6, CR7, CR8, CR9,
    CR10, CR11, CR12, CR13, CR14,
    CR15, DR0, DR1, DR2, DR3, DR4,
    DR5, DR6, DR7, DR8, DR9, DR10,
    DR11, DR12, DR13, DR14, DR15,
    FP0, FP1, FP2, FP3, FP4, FP5,
    FP6, FP7, K0, K1, K2, K3,
    K4, K5, K6, K7, MM0, MM1,
    MM2, MM3, MM4, MM5, MM6, MM7,
    R8, R9, R10, R11, R12, R13,
    R14, R15, ST0, ST1, ST2, ST3,
    ST4, ST5, ST6, ST7, XMM0, XMM1,
    XMM2, XMM3, XMM4, XMM5, XMM6,
    XMM7, XMM8, XMM9, XMM10, XMM11,
    XMM12, XMM13, XMM14, XMM15, XMM16,
    XMM17, XMM18, XMM19, XMM20, XMM21,
    XMM22, XMM23, XMM24, XMM25, XMM26,
    XMM27, XMM28, XMM29, XMM30, XMM31,
    YMM0, YMM1, YMM2, YMM3, YMM4,
    YMM5, YMM6, YMM7, YMM8, YMM9,
    YMM10, YMM11, YMM12, YMM13, YMM14,
    YMM15, YMM16, YMM17, YMM18, YMM19,
    YMM20, YMM21, YMM22, YMM23, YMM24,
    YMM25, YMM26, YMM27, YMM28, YMM29,
    YMM30, YMM31, ZMM0, ZMM1, ZMM2,
    ZMM3, ZMM4, ZMM5, ZMM6, ZMM7,
    ZMM8, ZMM9, ZMM10, ZMM11, ZMM12,
    ZMM13, ZMM14, ZMM15, ZMM16, ZMM17,
    ZMM18, ZMM19, ZMM20, ZMM21, ZMM22,
    ZMM23, ZMM24, ZMM25, ZMM26, ZMM27,
    ZMM28, ZMM29, ZMM30, ZMM31, R8B,
    R9B, R10B, R11B, R12B, R13B,
    R14B, R15B, R8D, R9D, R10D, R11D,
    R12D, R13D, R14D, R15D, R8W, R9W,
    R10W, R11W, R12W, R13W, R14W,
    R15W, ENDING ##  <-- mark the end of the list of registers


##  Sub-flags of EFLAGS

const
  EFLAGS_MODIFY_AF* = (1'i64 shl 0)
  EFLAGS_MODIFY_CF* = (1'i64 shl 1)
  EFLAGS_MODIFY_SF* = (1'i64 shl 2)
  EFLAGS_MODIFY_ZF* = (1'i64 shl 3)
  EFLAGS_MODIFY_PF* = (1'i64 shl 4)
  EFLAGS_MODIFY_OF* = (1'i64 shl 5)
  EFLAGS_MODIFY_TF* = (1'i64 shl 6)
  EFLAGS_MODIFY_IF* = (1'i64 shl 7)
  EFLAGS_MODIFY_DF* = (1'i64 shl 8)
  EFLAGS_MODIFY_NT* = (1'i64 shl 9)
  EFLAGS_MODIFY_RF* = (1'i64 shl 10)
  EFLAGS_PRIOR_OF* = (1'i64 shl 11)
  EFLAGS_PRIOR_SF* = (1'i64 shl 12)
  EFLAGS_PRIOR_ZF* = (1'i64 shl 13)
  EFLAGS_PRIOR_AF* = (1'i64 shl 14)
  EFLAGS_PRIOR_PF* = (1'i64 shl 15)
  EFLAGS_PRIOR_CF* = (1'i64 shl 16)
  EFLAGS_PRIOR_TF* = (1'i64 shl 17)
  EFLAGS_PRIOR_IF* = (1'i64 shl 18)
  EFLAGS_PRIOR_DF* = (1'i64 shl 19)
  EFLAGS_PRIOR_NT* = (1'i64 shl 20)
  EFLAGS_RESET_OF* = (1'i64 shl 21)
  EFLAGS_RESET_CF* = (1'i64 shl 22)
  EFLAGS_RESET_DF* = (1'i64 shl 23)
  EFLAGS_RESET_IF* = (1'i64 shl 24)
  EFLAGS_RESET_SF* = (1'i64 shl 25)
  EFLAGS_RESET_AF* = (1'i64 shl 26)
  EFLAGS_RESET_TF* = (1'i64 shl 27)
  EFLAGS_RESET_NT* = (1'i64 shl 28)
  EFLAGS_RESET_PF* = (1'i64 shl 29)
  EFLAGS_SET_CF* = (1'i64 shl 30)
  EFLAGS_SET_DF* = (1'i64 shl 31)
  EFLAGS_SET_IF* = (1'i64 shl 32)
  EFLAGS_TEST_OF* = (1'i64 shl 33)
  EFLAGS_TEST_SF* = (1'i64 shl 34)
  EFLAGS_TEST_ZF* = (1'i64 shl 35)
  EFLAGS_TEST_PF* = (1'i64 shl 36)
  EFLAGS_TEST_CF* = (1'i64 shl 37)
  EFLAGS_TEST_NT* = (1'i64 shl 38)
  EFLAGS_TEST_DF* = (1'i64 shl 39)
  EFLAGS_UNDEFINED_OF* = (1'i64 shl 40)
  EFLAGS_UNDEFINED_SF* = (1'i64 shl 41)
  EFLAGS_UNDEFINED_ZF* = (1'i64 shl 42)
  EFLAGS_UNDEFINED_PF* = (1'i64 shl 43)
  EFLAGS_UNDEFINED_AF* = (1'i64 shl 44)
  EFLAGS_UNDEFINED_CF* = (1'i64 shl 45)
  EFLAGS_RESET_RF* = (1'i64 shl 46)
  EFLAGS_TEST_RF* = (1'i64 shl 47)
  EFLAGS_TEST_IF* = (1'i64 shl 48)
  EFLAGS_TEST_TF* = (1'i64 shl 49)
  EFLAGS_TEST_AF* = (1'i64 shl 50)
  EFLAGS_RESET_ZF* = (1'i64 shl 51)
  EFLAGS_SET_OF* = (1'i64 shl 52)
  EFLAGS_SET_SF* = (1'i64 shl 53)
  EFLAGS_SET_ZF* = (1'i64 shl 54)
  EFLAGS_SET_AF* = (1'i64 shl 55)
  EFLAGS_SET_PF* = (1'i64 shl 56)
  EFLAGS_RESET_0F* = (1'i64 shl 57)
  EFLAGS_RESET_AC* = (1'i64 shl 58)
  FPU_FLAGS_MODIFY_C0* = (1'i64 shl 0)
  FPU_FLAGS_MODIFY_C1* = (1'i64 shl 1)
  FPU_FLAGS_MODIFY_C2* = (1'i64 shl 2)
  FPU_FLAGS_MODIFY_C3* = (1'i64 shl 3)
  FPU_FLAGS_RESET_C0* = (1'i64 shl 4)
  FPU_FLAGS_RESET_C1* = (1'i64 shl 5)
  FPU_FLAGS_RESET_C2* = (1'i64 shl 6)
  FPU_FLAGS_RESET_C3* = (1'i64 shl 7)
  FPU_FLAGS_SET_C0* = (1'i64 shl 8)
  FPU_FLAGS_SET_C1* = (1'i64 shl 9)
  FPU_FLAGS_SET_C2* = (1'i64 shl 10)
  FPU_FLAGS_SET_C3* = (1'i64 shl 11)
  FPU_FLAGS_UNDEFINED_C0* = (1'i64 shl 12)
  FPU_FLAGS_UNDEFINED_C1* = (1'i64 shl 13)
  FPU_FLAGS_UNDEFINED_C2* = (1'i64 shl 14)
  FPU_FLAGS_UNDEFINED_C3* = (1'i64 shl 15)
  FPU_FLAGS_TEST_C0* = (1'i64 shl 16)
  FPU_FLAGS_TEST_C1* = (1'i64 shl 17)
  FPU_FLAGS_TEST_C2* = (1'i64 shl 18)
  FPU_FLAGS_TEST_C3* = (1'i64 shl 19)

## / Operand type for instruction's operands

type
  x86_op_type* {.pure.} = enum
    INVALID = 0           ## /< = CS_OP_INVALID (Uninitialized).
    REG               ## /< = CS_OP_REG (Register operand).
    IMM               ## /< = CS_OP_IMM (Immediate operand).
    MEM                ## /< = CS_OP_MEM (Memory operand).


## / XOP Code Condition type

type
  x86_xop_cc* {.pure.} = enum
    INVALID = 0,     ## /< Uninitialized.
    LT, LE, GT, GE, EQ,
    NEQ, FALSE, TRUE


## / AVX broadcast type

type
  x86_avx_bcast* {.pure.} = enum
    INVALID = 0,  ## /< Uninitialized.
    B2,          ## /< AVX512 broadcast type {1to2}
    B4,          ## /< AVX512 broadcast type {1to4}
    B8,          ## /< AVX512 broadcast type {1to8}
    B16          ## /< AVX512 broadcast type {1to16}


## / SSE Code Condition type

type
  x86_sse_cc* {.pure.} = enum
    INVALID = 0,     ## /< Uninitialized.
    EQ, LT, LE, UNORD, NEQ,
    NLT, NLE, ORD


## / AVX Code Condition type

type
  x86_avx_cc* {.pure.} = enum
    INVALID = 0,     ## /< Uninitialized.
    EQ, LT, LE, UNORD, NEQ,
    NLT, NLE, ORD, EQ_UQ,
    NGE, NGT, FALSE, NEQ_OQ,
    GE, GT, TRUE, EQ_OS,
    LT_OQ, LE_OQ, UNORD_S, NEQ_US,
    NLT_UQ, NLE_UQ, ORD_S, EQ_US,
    NGE_UQ, NGT_UQ, FALSE_OS, NEQ_OS,
    GE_OQ, GT_OQ, TRUE_US


## / AVX static rounding mode type

type
  x86_avx_rm* {.pure.} = enum
    INVALID = 0,     ## /< Uninitialized.
    RN,            ## /< Round to nearest
    RD,            ## /< Round down
    RU,            ## /< Round up
    RZ             ## /< Round toward zero


## / Instruction prefixes - to be used in cs_x86.prefix[]

type
  x86_prefix* {.pure.} = enum
    INVALID = 0,
    ES = 0x26,       ## /< segment override ES (cs_x86.prefix[1]
    CS = 0x2e,       ## /< segment override CS (cs_x86.prefix[1]
    SS = 0x36,       ## /< segment override SS (cs_x86.prefix[1]
    DS = 0x3e,       ## /< segment override DS (cs_x86.prefix[1]
    FS = 0x64,       ## /< segment override FS (cs_x86.prefix[1]
    GS = 0x65,       ## /< segment override GS (cs_x86.prefix[1]
    OPSIZE = 0x66,   ## /< operand-size override (cs_x86.prefix[2]
    ADDRSIZE = 0x67, ## /< address-size override (cs_x86.prefix[3]
    LOCK = 0xf0,     ## /< lock (cs_x86.prefix[0]
    REPNE = 0xf2,    ## /< repne/repnz (cs_x86.prefix[0]
    REP = 0xf3       ## /< rep (cs_x86.prefix[0]

const
  REPE = REP

## / Instruction's operand referring to memory
## / This is associated with OP_MEM operand type above

type
  x86_op_mem* {.bycopy.} = object
    segment*: x86_reg          ## /< segment register (or INVALID if irrelevant)
    base*: x86_reg             ## /< base register (or INVALID if irrelevant)
    index*: x86_reg            ## /< index register (or INVALID if irrelevant)
    scale*: cint               ## /< scale for index register
    disp*: int64_t             ## /< displacement value


## / Instruction operand

type
  INNER_C_UNION_x86_296* {.bycopy, union.} = object
    reg*: x86_reg              ## /< register value for REG operand
    imm*: int64_t              ## /< immediate value for IMM operand
    mem*: x86_op_mem           ## /< base/index/scale/disp value for MEM operand

  cs_x86_op* {.bycopy.} = object
    `type`*: x86_op_type       ## /< operand type
    storage*: INNER_C_UNION_x86_296
    size*: uint8_t ## / How is this operand accessed? (READ, WRITE or READ|WRITE)
                 ## / This field is combined of cs_ac_type.
                 ## / NOTE: this field is irrelevant if engine is compiled in DIET mode.
    access*: uint8_t           ## / AVX broadcast type, or 0 if irrelevant
    avx_bcast*: x86_avx_bcast  ## / AVX zero opmask {z}
    avx_zero_opmask*: bool

  cs_x86_encoding* {.bycopy.} = object
    modrm_offset*: uint8_t     ## / ModR/M offset, or 0 when irrelevant

    disp_offset*: uint8_t
    disp_size*: uint8_t        ## / Immediate offset, or 0 when irrelevant.
    imm_offset*: uint8_t
    imm_size*: uint8_t


## / Instruction structure

type
  INNER_C_UNION_x86_381* {.bycopy, union.} = object
    eflags*: uint64_t          ## / EFLAGS updated by this instruction.
                    ## / This can be formed from OR combination of EFLAGS_* symbols in x86.h
    ## / FPU_FLAGS updated by this instruction.
    ## / This can be formed from OR combination of FPU_FLAGS_* symbols in x86.h
    fpu_flags*: uint64_t

  cs_x86* {.bycopy.} = object
    prefix*: array[4, uint8_t] ## / Instruction prefix, which can be up to 4 bytes.
                            ## / A prefix byte gets value 0 when irrelevant.
                            ## / prefix[0] indicates REP/REPNE/LOCK prefix (See REP/REPNE/LOCK above)
                            ## / prefix[1] indicates segment override (irrelevant for x86_64):
                            ## / See CS/SS/DS/ES/FS/GS above.
                            ## / prefix[2] indicates operand-size override (OPSIZE)
                            ## / prefix[3] indicates address-size override (ADDRSIZE)
    ## / Instruction opcode, which can be from 1 to 4 bytes in size.
    ## / This contains VEX opcode as well.
    ## / An trailing opcode byte gets value 0 when irrelevant.
    opcode*: array[4, uint8_t]  ## / REX prefix: only a non-zero value is relevant for x86_64
    rex*: uint8_t              ## / Address size, which can be overridden with above prefix[5].
    addr_size*: uint8_t        ## / ModR/M byte
    modrm*: uint8_t            ## / SIB value, or 0 when irrelevant.
    sib*: uint8_t              ## / Displacement value, valid if encoding.disp_offset != 0
    disp*: int64_t             ## / SIB index register, or INVALID when irrelevant.
    sib_index*: x86_reg        ## / SIB scale, only applicable if sib_index is valid.
    sib_scale*: int8_t         ## / SIB base register, or INVALID when irrelevant.
    sib_base*: x86_reg         ## / XOP Code Condition
    xop_cc*: x86_xop_cc        ## / SSE Code Condition
    sse_cc*: x86_sse_cc        ## / AVX Code Condition
    avx_cc*: x86_avx_cc        ## / AVX Suppress all Exception
    avx_sae*: bool             ## / AVX static rounding mode
    avx_rm*: x86_avx_rm
    flags*: INNER_C_UNION_x86_381
    op_count*: uint8_t
    operands*: array[8, cs_x86_op] ## /< operands for this instruction.
    encoding*: cs_x86_encoding ## /< encoding information


## / X86 instructions

type
  x86_insn* {.pure.} = enum
    INVALID = 0, AAA, AAD, AAM, AAS,
    FABS, ADC, ADCX, ADD, ADDPD,
    ADDPS, ADDSD, ADDSS, ADDSUBPD, ADDSUBPS,
    FADD, FIADD, FADDP, ADOX, AESDECLAST,
    AESDEC, AESENCLAST, AESENC, AESIMC,
    AESKEYGENASSIST, AND, ANDN, ANDNPD,
    ANDNPS, ANDPD, ANDPS, ARPL, BEXTR,
    BLCFILL, BLCI, BLCIC, BLCMSK, BLCS,
    BLENDPD, BLENDPS, BLENDVPD, BLENDVPS,
    BLSFILL, BLSI, BLSIC, BLSMSK, BLSR,
    BOUND, BSF, BSR, BSWAP, BT, BTC,
    BTR, BTS, BZHI, CALL, CBW, CDQ,
    CDQE, FCHS, CLAC, CLC, CLD,
    CLFLUSH, CLFLUSHOPT, CLGI, CLI, CLTS,
    CLWB, CMC, CMOVA, CMOVAE, CMOVB,
    CMOVBE, FCMOVBE, FCMOVB, CMOVE, FCMOVE,
    CMOVG, CMOVGE, CMOVL, CMOVLE, FCMOVNBE,
    FCMOVNB, CMOVNE, FCMOVNE, CMOVNO,
    CMOVNP, FCMOVNU, CMOVNS, CMOVO, CMOVP,
    FCMOVU, CMOVS, CMP, CMPSB, CMPSQ,
    CMPSW, CMPXCHG16B, CMPXCHG, CMPXCHG8B,
    COMISD, COMISS, FCOMP, FCOMIP, FCOMI,
    FCOM, FCOS, CPUID, CQO, CRC32,
    CVTDQ2PD, CVTDQ2PS, CVTPD2DQ, CVTPD2PS,
    CVTPS2DQ, CVTPS2PD, CVTSD2SI, CVTSD2SS,
    CVTSI2SD, CVTSI2SS, CVTSS2SD, CVTSS2SI,
    CVTTPD2DQ, CVTTPS2DQ, CVTTSD2SI, CVTTSS2SI,
    CWD, CWDE, DAA, DAS, DATA16, DEC,
    DIV, DIVPD, DIVPS, FDIVR, FIDIVR,
    FDIVRP, DIVSD, DIVSS, FDIV, FIDIV,
    FDIVP, DPPD, DPPS, RET, ENCLS,
    ENCLU, ENTER, EXTRACTPS, EXTRQ, F2XM1,
    LCALL, LJMP, FBLD, FBSTP, FCOMPP,
    FDECSTP, FEMMS, FFREE, FICOM, FICOMP,
    FINCSTP, FLDCW, FLDENV, FLDL2E, FLDL2T,
    FLDLG2, FLDLN2, FLDPI, FNCLEX, FNINIT,
    FNOP, FNSTCW, FNSTSW, FPATAN, FPREM,
    FPREM1, FPTAN, FFREEP, FRNDINT, FRSTOR,
    FNSAVE, FSCALE, FSETPM, FSINCOS,
    FNSTENV, FXAM, FXRSTOR, FXRSTOR64,
    FXSAVE, FXSAVE64, FXTRACT, FYL2X,
    FYL2XP1, MOVAPD, MOVAPS, ORPD, ORPS,
    VMOVAPD, VMOVAPS, XORPD, XORPS, GETSEC,
    HADDPD, HADDPS, HLT, HSUBPD, HSUBPS,
    IDIV, FILD, IMUL, IN, INC, INSB,
    INSERTPS, INSERTQ, INSD, INSW, INT,
    INT1, INT3, INTO, INVD, INVEPT,
    INVLPG, INVLPGA, INVPCID, INVVPID, IRET,
    IRETD, IRETQ, FISTTP, FIST, FISTP,
    UCOMISD, UCOMISS, VCOMISD, VCOMISS,
    VCVTSD2SS, VCVTSI2SD, VCVTSI2SS, VCVTSS2SD,
    VCVTTSD2SI, VCVTTSD2USI, VCVTTSS2SI,
    VCVTTSS2USI, VCVTUSI2SD, VCVTUSI2SS, VUCOMISD,
    VUCOMISS, JAE, JA, JBE, JB, JCXZ,
    JECXZ, JE, JGE, JG, JLE, JL,
    JMP, JNE, JNO, JNP, JNS, JO,
    JP, JRCXZ, JS, KANDB, KANDD,
    KANDNB, KANDND, KANDNQ, KANDNW, KANDQ,
    KANDW, KMOVB, KMOVD, KMOVQ, KMOVW,
    KNOTB, KNOTD, KNOTQ, KNOTW, KORB,
    KORD, KORQ, KORTESTB, KORTESTD,
    KORTESTQ, KORTESTW, KORW, KSHIFTLB,
    KSHIFTLD, KSHIFTLQ, KSHIFTLW, KSHIFTRB,
    KSHIFTRD, KSHIFTRQ, KSHIFTRW, KUNPCKBW,
    KXNORB, KXNORD, KXNORQ, KXNORW, KXORB,
    KXORD, KXORQ, KXORW, LAHF, LAR,
    LDDQU, LDMXCSR, LDS, FLDZ, FLD1,
    FLD, LEA, LEAVE, LES, LFENCE,
    LFS, LGDT, LGS, LIDT, LLDT, LMSW,
    OR, SUB, XOR, LODSB, LODSD,
    LODSQ, LODSW, LOOP, LOOPE, LOOPNE,
    RETF, RETFQ, LSL, LSS, LTR, XADD,
    LZCNT, MASKMOVDQU, MAXPD, MAXPS, MAXSD,
    MAXSS, MFENCE, MINPD, MINPS, MINSD,
    MINSS, CVTPD2PI, CVTPI2PD, CVTPI2PS,
    CVTPS2PI, CVTTPD2PI, CVTTPS2PI, EMMS,
    MASKMOVQ, MOVD, MOVDQ2Q, MOVNTQ,
    MOVQ2DQ, MOVQ, PABSB, PABSD, PABSW,
    PACKSSDW, PACKSSWB, PACKUSWB, PADDB,
    PADDD, PADDQ, PADDSB, PADDSW, PADDUSB,
    PADDUSW, PADDW, PALIGNR, PANDN, PAND,
    PAVGB, PAVGW, PCMPEQB, PCMPEQD, PCMPEQW,
    PCMPGTB, PCMPGTD, PCMPGTW, PEXTRW,
    PHADDSW, PHADDW, PHADDD, PHSUBD,
    PHSUBSW, PHSUBW, PINSRW, PMADDUBSW,
    PMADDWD, PMAXSW, PMAXUB, PMINSW, PMINUB,
    PMOVMSKB, PMULHRSW, PMULHUW, PMULHW,
    PMULLW, PMULUDQ, POR, PSADBW, PSHUFB,
    PSHUFW, PSIGNB, PSIGND, PSIGNW, PSLLD,
    PSLLQ, PSLLW, PSRAD, PSRAW, PSRLD,
    PSRLQ, PSRLW, PSUBB, PSUBD, PSUBQ,
    PSUBSB, PSUBSW, PSUBUSB, PSUBUSW, PSUBW,
    PUNPCKHBW, PUNPCKHDQ, PUNPCKHWD, PUNPCKLBW,
    PUNPCKLDQ, PUNPCKLWD, PXOR, MONITOR,
    MONTMUL, MOV, MOVABS, MOVBE, MOVDDUP,
    MOVDQA, MOVDQU, MOVHLPS, MOVHPD, MOVHPS,
    MOVLHPS, MOVLPD, MOVLPS, MOVMSKPD,
    MOVMSKPS, MOVNTDQA, MOVNTDQ, MOVNTI,
    MOVNTPD, MOVNTPS, MOVNTSD, MOVNTSS,
    MOVSB, MOVSD, MOVSHDUP, MOVSLDUP, MOVSQ,
    MOVSS, MOVSW, MOVSX, MOVSXD, MOVUPD,
    MOVUPS, MOVZX, MPSADBW, MUL, MULPD,
    MULPS, MULSD, MULSS, MULX, FMUL,
    FIMUL, FMULP, MWAIT, NEG, NOP,
    NOT, OUT, OUTSB, OUTSD, OUTSW,
    PACKUSDW, PAUSE, PAVGUSB, PBLENDVB,
    PBLENDW, PCLMULQDQ, PCMPEQQ, PCMPESTRI,
    PCMPESTRM, PCMPGTQ, PCMPISTRI, PCMPISTRM,
    PCOMMIT, PDEP, PEXT, PEXTRB, PEXTRD,
    PEXTRQ, PF2ID, PF2IW, PFACC, PFADD,
    PFCMPEQ, PFCMPGE, PFCMPGT, PFMAX, PFMIN,
    PFMUL, PFNACC, PFPNACC, PFRCPIT1,
    PFRCPIT2, PFRCP, PFRSQIT1, PFRSQRT,
    PFSUBR, PFSUB, PHMINPOSUW, PI2FD, PI2FW,
    PINSRB, PINSRD, PINSRQ, PMAXSB, PMAXSD,
    PMAXUD, PMAXUW, PMINSB, PMINSD, PMINUD,
    PMINUW, PMOVSXBD, PMOVSXBQ, PMOVSXBW,
    PMOVSXDQ, PMOVSXWD, PMOVSXWQ, PMOVZXBD,
    PMOVZXBQ, PMOVZXBW, PMOVZXDQ, PMOVZXWD,
    PMOVZXWQ, PMULDQ, PMULHRW, PMULLD, POP,
    POPAW, POPAL, POPCNT, POPF, POPFD,
    POPFQ, PREFETCH, PREFETCHNTA, PREFETCHT0,
    PREFETCHT1, PREFETCHT2, PREFETCHW, PSHUFD,
    PSHUFHW, PSHUFLW, PSLLDQ, PSRLDQ,
    PSWAPD, PTEST, PUNPCKHQDQ, PUNPCKLQDQ,
    PUSH, PUSHAW, PUSHAL, PUSHF, PUSHFD,
    PUSHFQ, RCL, RCPPS, RCPSS, RCR,
    RDFSBASE, RDGSBASE, RDMSR, RDPMC,
    RDRAND, RDSEED, RDTSC, RDTSCP, ROL,
    ROR, RORX, ROUNDPD, ROUNDPS, ROUNDSD,
    ROUNDSS, RSM, RSQRTPS, RSQRTSS, SAHF,
    SAL, SALC, SAR, SARX, SBB, SCASB,
    SCASD, SCASQ, SCASW, SETAE, SETA,
    SETBE, SETB, SETE, SETGE, SETG,
    SETLE, SETL, SETNE, SETNO, SETNP,
    SETNS, SETO, SETP, SETS, SFENCE,
    SGDT, SHA1MSG1, SHA1MSG2, SHA1NEXTE,
    SHA1RNDS4, SHA256MSG1, SHA256MSG2, SHA256RNDS2,
    SHL, SHLD, SHLX, SHR, SHRD, SHRX,
    SHUFPD, SHUFPS, SIDT, FSIN, SKINIT,
    SLDT, SMSW, SQRTPD, SQRTPS, SQRTSD,
    SQRTSS, FSQRT, STAC, STC, STD,
    STGI, STI, STMXCSR, STOSB, STOSD,
    STOSQ, STOSW, STR, FST, FSTP,
    FSTPNCE, FXCH, SUBPD, SUBPS, FSUBR,
    FISUBR, FSUBRP, SUBSD, SUBSS, FSUB,
    FISUB, FSUBP, SWAPGS, SYSCALL, SYSENTER,
    SYSEXIT, SYSRET, T1MSKC, TEST, UD2,
    FTST, TZCNT, TZMSK, FUCOMIP, FUCOMI,
    FUCOMPP, FUCOMP, FUCOM, UD2B, UNPCKHPD,
    UNPCKHPS, UNPCKLPD, UNPCKLPS, VADDPD,
    VADDPS, VADDSD, VADDSS, VADDSUBPD,
    VADDSUBPS, VAESDECLAST, VAESDEC, VAESENCLAST,
    VAESENC, VAESIMC, VAESKEYGENASSIST, VALIGND,
    VALIGNQ, VANDNPD, VANDNPS, VANDPD,
    VANDPS, VBLENDMPD, VBLENDMPS, VBLENDPD,
    VBLENDPS, VBLENDVPD, VBLENDVPS, VBROADCASTF128,
    VBROADCASTI32X4, VBROADCASTI64X4, VBROADCASTSD,
    VBROADCASTSS, VCOMPRESSPD, VCOMPRESSPS,
    VCVTDQ2PD, VCVTDQ2PS, VCVTPD2DQX, VCVTPD2DQ,
    VCVTPD2PSX, VCVTPD2PS, VCVTPD2UDQ, VCVTPH2PS,
    VCVTPS2DQ, VCVTPS2PD, VCVTPS2PH, VCVTPS2UDQ,
    VCVTSD2SI, VCVTSD2USI, VCVTSS2SI, VCVTSS2USI,
    VCVTTPD2DQX, VCVTTPD2DQ, VCVTTPD2UDQ,
    VCVTTPS2DQ, VCVTTPS2UDQ, VCVTUDQ2PD,
    VCVTUDQ2PS, VDIVPD, VDIVPS, VDIVSD,
    VDIVSS, VDPPD, VDPPS, VERR, VERW,
    VEXP2PD, VEXP2PS, VEXPANDPD, VEXPANDPS,
    VEXTRACTF128, VEXTRACTF32X4, VEXTRACTF64X4,
    VEXTRACTI128, VEXTRACTI32X4, VEXTRACTI64X4,
    VEXTRACTPS, VFMADD132PD, VFMADD132PS, VFMADDPD,
    VFMADD213PD, VFMADD231PD, VFMADDPS,
    VFMADD213PS, VFMADD231PS, VFMADDSD,
    VFMADD213SD, VFMADD132SD, VFMADD231SD,
    VFMADDSS, VFMADD213SS, VFMADD132SS,
    VFMADD231SS, VFMADDSUB132PD, VFMADDSUB132PS,
    VFMADDSUBPD, VFMADDSUB213PD, VFMADDSUB231PD,
    VFMADDSUBPS, VFMADDSUB213PS, VFMADDSUB231PS,
    VFMSUB132PD, VFMSUB132PS, VFMSUBADD132PD,
    VFMSUBADD132PS, VFMSUBADDPD, VFMSUBADD213PD,
    VFMSUBADD231PD, VFMSUBADDPS, VFMSUBADD213PS,
    VFMSUBADD231PS, VFMSUBPD, VFMSUB213PD,
    VFMSUB231PD, VFMSUBPS, VFMSUB213PS,
    VFMSUB231PS, VFMSUBSD, VFMSUB213SD,
    VFMSUB132SD, VFMSUB231SD, VFMSUBSS,
    VFMSUB213SS, VFMSUB132SS, VFMSUB231SS,
    VFNMADD132PD, VFNMADD132PS, VFNMADDPD,
    VFNMADD213PD, VFNMADD231PD, VFNMADDPS,
    VFNMADD213PS, VFNMADD231PS, VFNMADDSD,
    VFNMADD213SD, VFNMADD132SD, VFNMADD231SD,
    VFNMADDSS, VFNMADD213SS, VFNMADD132SS,
    VFNMADD231SS, VFNMSUB132PD, VFNMSUB132PS,
    VFNMSUBPD, VFNMSUB213PD, VFNMSUB231PD,
    VFNMSUBPS, VFNMSUB213PS, VFNMSUB231PS,
    VFNMSUBSD, VFNMSUB213SD, VFNMSUB132SD,
    VFNMSUB231SD, VFNMSUBSS, VFNMSUB213SS,
    VFNMSUB132SS, VFNMSUB231SS, VFRCZPD, VFRCZPS,
    VFRCZSD, VFRCZSS, VORPD, VORPS, VXORPD,
    VXORPS, VGATHERDPD, VGATHERDPS, VGATHERPF0DPD,
    VGATHERPF0DPS, VGATHERPF0QPD, VGATHERPF0QPS,
    VGATHERPF1DPD, VGATHERPF1DPS, VGATHERPF1QPD,
    VGATHERPF1QPS, VGATHERQPD, VGATHERQPS, VHADDPD,
    VHADDPS, VHSUBPD, VHSUBPS, VINSERTF128,
    VINSERTF32X4, VINSERTF32X8, VINSERTF64X2,
    VINSERTF64X4, VINSERTI128, VINSERTI32X4,
    VINSERTI32X8, VINSERTI64X2, VINSERTI64X4,
    VINSERTPS, VLDDQU, VLDMXCSR, VMASKMOVDQU,
    VMASKMOVPD, VMASKMOVPS, VMAXPD, VMAXPS,
    VMAXSD, VMAXSS, VMCALL, VMCLEAR, VMFUNC,
    VMINPD, VMINPS, VMINSD, VMINSS,
    VMLAUNCH, VMLOAD, VMMCALL, VMOVQ,
    VMOVDDUP, VMOVD, VMOVDQA32, VMOVDQA64,
    VMOVDQA, VMOVDQU16, VMOVDQU32, VMOVDQU64,
    VMOVDQU8, VMOVDQU, VMOVHLPS, VMOVHPD,
    VMOVHPS, VMOVLHPS, VMOVLPD, VMOVLPS,
    VMOVMSKPD, VMOVMSKPS, VMOVNTDQA, VMOVNTDQ,
    VMOVNTPD, VMOVNTPS, VMOVSD, VMOVSHDUP,
    VMOVSLDUP, VMOVSS, VMOVUPD, VMOVUPS,
    VMPSADBW, VMPTRLD, VMPTRST, VMREAD,
    VMRESUME, VMRUN, VMSAVE, VMULPD, VMULPS,
    VMULSD, VMULSS, VMWRITE, VMXOFF, VMXON,
    VPABSB, VPABSD, VPABSQ, VPABSW,
    VPACKSSDW, VPACKSSWB, VPACKUSDW, VPACKUSWB,
    VPADDB, VPADDD, VPADDQ, VPADDSB,
    VPADDSW, VPADDUSB, VPADDUSW, VPADDW,
    VPALIGNR, VPANDD, VPANDND, VPANDNQ,
    VPANDN, VPANDQ, VPAND, VPAVGB, VPAVGW,
    VPBLENDD, VPBLENDMB, VPBLENDMD, VPBLENDMQ,
    VPBLENDMW, VPBLENDVB, VPBLENDW, VPBROADCASTB,
    VPBROADCASTD, VPBROADCASTMB2Q, VPBROADCASTMW2D,
    VPBROADCASTQ, VPBROADCASTW, VPCLMULQDQ, VPCMOV,
    VPCMPB, VPCMPD, VPCMPEQB, VPCMPEQD,
    VPCMPEQQ, VPCMPEQW, VPCMPESTRI, VPCMPESTRM,
    VPCMPGTB, VPCMPGTD, VPCMPGTQ, VPCMPGTW,
    VPCMPISTRI, VPCMPISTRM, VPCMPQ, VPCMPUB,
    VPCMPUD, VPCMPUQ, VPCMPUW, VPCMPW,
    VPCOMB, VPCOMD, VPCOMPRESSD, VPCOMPRESSQ,
    VPCOMQ, VPCOMUB, VPCOMUD, VPCOMUQ,
    VPCOMUW, VPCOMW, VPCONFLICTD, VPCONFLICTQ,
    VPERM2F128, VPERM2I128, VPERMD, VPERMI2D,
    VPERMI2PD, VPERMI2PS, VPERMI2Q, VPERMIL2PD,
    VPERMIL2PS, VPERMILPD, VPERMILPS, VPERMPD,
    VPERMPS, VPERMQ, VPERMT2D, VPERMT2PD,
    VPERMT2PS, VPERMT2Q, VPEXPANDD, VPEXPANDQ,
    VPEXTRB, VPEXTRD, VPEXTRQ, VPEXTRW,
    VPGATHERDD, VPGATHERDQ, VPGATHERQD, VPGATHERQQ,
    VPHADDBD, VPHADDBQ, VPHADDBW, VPHADDDQ,
    VPHADDD, VPHADDSW, VPHADDUBD, VPHADDUBQ,
    VPHADDUBW, VPHADDUDQ, VPHADDUWD, VPHADDUWQ,
    VPHADDWD, VPHADDWQ, VPHADDW, VPHMINPOSUW,
    VPHSUBBW, VPHSUBDQ, VPHSUBD, VPHSUBSW,
    VPHSUBWD, VPHSUBW, VPINSRB, VPINSRD,
    VPINSRQ, VPINSRW, VPLZCNTD, VPLZCNTQ,
    VPMACSDD, VPMACSDQH, VPMACSDQL, VPMACSSDD,
    VPMACSSDQH, VPMACSSDQL, VPMACSSWD, VPMACSSWW,
    VPMACSWD, VPMACSWW, VPMADCSSWD, VPMADCSWD,
    VPMADDUBSW, VPMADDWD, VPMASKMOVD, VPMASKMOVQ,
    VPMAXSB, VPMAXSD, VPMAXSQ, VPMAXSW,
    VPMAXUB, VPMAXUD, VPMAXUQ, VPMAXUW,
    VPMINSB, VPMINSD, VPMINSQ, VPMINSW,
    VPMINUB, VPMINUD, VPMINUQ, VPMINUW,
    VPMOVDB, VPMOVDW, VPMOVM2B, VPMOVM2D,
    VPMOVM2Q, VPMOVM2W, VPMOVMSKB, VPMOVQB,
    VPMOVQD, VPMOVQW, VPMOVSDB, VPMOVSDW,
    VPMOVSQB, VPMOVSQD, VPMOVSQW, VPMOVSXBD,
    VPMOVSXBQ, VPMOVSXBW, VPMOVSXDQ, VPMOVSXWD,
    VPMOVSXWQ, VPMOVUSDB, VPMOVUSDW, VPMOVUSQB,
    VPMOVUSQD, VPMOVUSQW, VPMOVZXBD, VPMOVZXBQ,
    VPMOVZXBW, VPMOVZXDQ, VPMOVZXWD, VPMOVZXWQ,
    VPMULDQ, VPMULHRSW, VPMULHUW, VPMULHW,
    VPMULLD, VPMULLQ, VPMULLW, VPMULUDQ,
    VPORD, VPORQ, VPOR, VPPERM, VPROTB,
    VPROTD, VPROTQ, VPROTW, VPSADBW,
    VPSCATTERDD, VPSCATTERDQ, VPSCATTERQD,
    VPSCATTERQQ, VPSHAB, VPSHAD, VPSHAQ,
    VPSHAW, VPSHLB, VPSHLD, VPSHLQ, VPSHLW,
    VPSHUFB, VPSHUFD, VPSHUFHW, VPSHUFLW,
    VPSIGNB, VPSIGND, VPSIGNW, VPSLLDQ,
    VPSLLD, VPSLLQ, VPSLLVD, VPSLLVQ,
    VPSLLW, VPSRAD, VPSRAQ, VPSRAVD,
    VPSRAVQ, VPSRAW, VPSRLDQ, VPSRLD,
    VPSRLQ, VPSRLVD, VPSRLVQ, VPSRLW,
    VPSUBB, VPSUBD, VPSUBQ, VPSUBSB,
    VPSUBSW, VPSUBUSB, VPSUBUSW, VPSUBW,
    VPTESTMD, VPTESTMQ, VPTESTNMD, VPTESTNMQ,
    VPTEST, VPUNPCKHBW, VPUNPCKHDQ, VPUNPCKHQDQ,
    VPUNPCKHWD, VPUNPCKLBW, VPUNPCKLDQ,
    VPUNPCKLQDQ, VPUNPCKLWD, VPXORD, VPXORQ,
    VPXOR, VRCP14PD, VRCP14PS, VRCP14SD,
    VRCP14SS, VRCP28PD, VRCP28PS, VRCP28SD,
    VRCP28SS, VRCPPS, VRCPSS, VRNDSCALEPD,
    VRNDSCALEPS, VRNDSCALESD, VRNDSCALESS,
    VROUNDPD, VROUNDPS, VROUNDSD, VROUNDSS,
    VRSQRT14PD, VRSQRT14PS, VRSQRT14SD, VRSQRT14SS,
    VRSQRT28PD, VRSQRT28PS, VRSQRT28SD, VRSQRT28SS,
    VRSQRTPS, VRSQRTSS, VSCATTERDPD, VSCATTERDPS,
    VSCATTERPF0DPD, VSCATTERPF0DPS, VSCATTERPF0QPD,
    VSCATTERPF0QPS, VSCATTERPF1DPD, VSCATTERPF1DPS,
    VSCATTERPF1QPD, VSCATTERPF1QPS, VSCATTERQPD,
    VSCATTERQPS, VSHUFPD, VSHUFPS, VSQRTPD,
    VSQRTPS, VSQRTSD, VSQRTSS, VSTMXCSR,
    VSUBPD, VSUBPS, VSUBSD, VSUBSS, VTESTPD,
    VTESTPS, VUNPCKHPD, VUNPCKHPS, VUNPCKLPD,
    VUNPCKLPS, VZEROALL, VZEROUPPER, WAIT,
    WBINVD, WRFSBASE, WRGSBASE, WRMSR,
    XABORT, XACQUIRE, XBEGIN, XCHG,
    XCRYPTCBC, XCRYPTCFB, XCRYPTCTR, XCRYPTECB,
    XCRYPTOFB, XEND, XGETBV, XLATB,
    XRELEASE, XRSTOR, XRSTOR64, XRSTORS,
    XRSTORS64, XSAVE, XSAVE64, XSAVEC,
    XSAVEC64, XSAVEOPT, XSAVEOPT64, XSAVES,
    XSAVES64, XSETBV, XSHA1, XSHA256,
    XSTORE, XTEST, FDISI8087_NOP, FENI8087_NOP, ##  pseudo instructions
    CMPSS, CMPEQSS, CMPLTSS, CMPLESS,
    CMPUNORDSS, CMPNEQSS, CMPNLTSS, CMPNLESS,
    CMPORDSS, CMPSD, CMPEQSD, CMPLTSD,
    CMPLESD, CMPUNORDSD, CMPNEQSD, CMPNLTSD,
    CMPNLESD, CMPORDSD, CMPPS, CMPEQPS,
    CMPLTPS, CMPLEPS, CMPUNORDPS, CMPNEQPS,
    CMPNLTPS, CMPNLEPS, CMPORDPS, CMPPD,
    CMPEQPD, CMPLTPD, CMPLEPD, CMPUNORDPD,
    CMPNEQPD, CMPNLTPD, CMPNLEPD, CMPORDPD,
    VCMPSS, VCMPEQSS, VCMPLTSS, VCMPLESS,
    VCMPUNORDSS, VCMPNEQSS, VCMPNLTSS, VCMPNLESS,
    VCMPORDSS, VCMPEQ_UQSS, VCMPNGESS, VCMPNGTSS,
    VCMPFALSESS, VCMPNEQ_OQSS, VCMPGESS, VCMPGTSS,
    VCMPTRUESS, VCMPEQ_OSSS, VCMPLT_OQSS,
    VCMPLE_OQSS, VCMPUNORD_SSS, VCMPNEQ_USSS,
    VCMPNLT_UQSS, VCMPNLE_UQSS, VCMPORD_SSS,
    VCMPEQ_USSS, VCMPNGE_UQSS, VCMPNGT_UQSS,
    VCMPFALSE_OSSS, VCMPNEQ_OSSS, VCMPGE_OQSS,
    VCMPGT_OQSS, VCMPTRUE_USSS, VCMPSD, VCMPEQSD,
    VCMPLTSD, VCMPLESD, VCMPUNORDSD, VCMPNEQSD,
    VCMPNLTSD, VCMPNLESD, VCMPORDSD, VCMPEQ_UQSD,
    VCMPNGESD, VCMPNGTSD, VCMPFALSESD,
    VCMPNEQ_OQSD, VCMPGESD, VCMPGTSD, VCMPTRUESD,
    VCMPEQ_OSSD, VCMPLT_OQSD, VCMPLE_OQSD,
    VCMPUNORD_SSD, VCMPNEQ_USSD, VCMPNLT_UQSD,
    VCMPNLE_UQSD, VCMPORD_SSD, VCMPEQ_USSD,
    VCMPNGE_UQSD, VCMPNGT_UQSD, VCMPFALSE_OSSD,
    VCMPNEQ_OSSD, VCMPGE_OQSD, VCMPGT_OQSD,
    VCMPTRUE_USSD, VCMPPS, VCMPEQPS, VCMPLTPS,
    VCMPLEPS, VCMPUNORDPS, VCMPNEQPS, VCMPNLTPS,
    VCMPNLEPS, VCMPORDPS, VCMPEQ_UQPS, VCMPNGEPS,
    VCMPNGTPS, VCMPFALSEPS, VCMPNEQ_OQPS, VCMPGEPS,
    VCMPGTPS, VCMPTRUEPS, VCMPEQ_OSPS, VCMPLT_OQPS,
    VCMPLE_OQPS, VCMPUNORD_SPS, VCMPNEQ_USPS,
    VCMPNLT_UQPS, VCMPNLE_UQPS, VCMPORD_SPS,
    VCMPEQ_USPS, VCMPNGE_UQPS, VCMPNGT_UQPS,
    VCMPFALSE_OSPS, VCMPNEQ_OSPS, VCMPGE_OQPS,
    VCMPGT_OQPS, VCMPTRUE_USPS, VCMPPD, VCMPEQPD,
    VCMPLTPD, VCMPLEPD, VCMPUNORDPD, VCMPNEQPD,
    VCMPNLTPD, VCMPNLEPD, VCMPORDPD, VCMPEQ_UQPD,
    VCMPNGEPD, VCMPNGTPD, VCMPFALSEPD,
    VCMPNEQ_OQPD, VCMPGEPD, VCMPGTPD, VCMPTRUEPD,
    VCMPEQ_OSPD, VCMPLT_OQPD, VCMPLE_OQPD,
    VCMPUNORD_SPD, VCMPNEQ_USPD, VCMPNLT_UQPD,
    VCMPNLE_UQPD, VCMPORD_SPD, VCMPEQ_USPD,
    VCMPNGE_UQPD, VCMPNGT_UQPD, VCMPFALSE_OSPD,
    VCMPNEQ_OSPD, VCMPGE_OQPD, VCMPGT_OQPD,
    VCMPTRUE_USPD, UD0, ENDBR32, ENDBR64, ENDING ##  mark the end of the list of insn


## / Group of X86 instructions

type
  x86_insn_group* {.pure.} = enum
    INVALID = 0,        ## /< = CS_INVALID
                      ##  Generic groups
                      ##  all jump instructions (conditional+direct+indirect jumps)
    JUMP,             ## /< = CS_JUMP
                 ##  all call instructions
    CALL,             ## /< = CS_CALL
                 ##  all return instructions
    RET,              ## /< = CS_RET
                ##  all interrupt instructions (int+syscall)
    INT,              ## /< = CS_INT
                ##  all interrupt return instructions
    IRET,             ## /< = CS_IRET
                 ##  all privileged instructions
    PRIVILEGE,        ## /< = CS_PRIVILEGE
                      ##  all relative branching instructions
    BRANCH_RELATIVE,  ## /< = CS_BRANCH_RELATIVE
                            ##  Architecture-specific groups
    VM = 128,           ## /< all virtualization instructions (VT-x + AMD-V)
    THREEDNOW, AES, ADX, AVX, AVX2,
    AVX512, BMI, BMI2, CMOV, F16C,
    FMA, FMA4, FSGSBASE, HLE, MMX,
    MODE32, MODE64, RTM, SHA, SSE1,
    SSE2, SSE3, SSE41, SSE42, SSE4A,
    SSSE3, PCLMUL, XOP, CDI, ERI,
    TBM, SIXTEEN_BITMODE, NOT64BITMODE, SGX, DQI,
    BWI, PFI, VLX, SMAP, NOVLX, FPU,
    ENDING

